{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTConfig(block_size=1024, vocab_size=100288, n_layer=16, n_head=16, n_embd=1024, attn_dropout=0.0, batch_size=4, epochs=2, device='cuda', clip_grad_norm_val=1.0, training_backend='nccl', learning_rate=0.0003, weight_decay=0.0001, eps=1e-08, betas=(0.9, 0.97), base_theta=10000.0, scale_factor=1.0, dtype=torch.bfloat16, fused_optimizer=True, do_init_params=True, model_init_seed=42)\n"
     ]
    }
   ],
   "source": [
    "gin.parse_config_file(\"config/gpt2-small.gin\")\n",
    "config = GPTConfig()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n",
      "Initialized model parameters!....\n"
     ]
    }
   ],
   "source": [
    "model = GPT(config, generator=torch.Generator(device=\"cpu\").manual_seed(42))\n",
    "# model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371.511232"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of parameters in terms of billions\n",
    "num_params = sum([param.nelement() for param in model.parameters()])\n",
    "num_params / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tiktoken\n",
    "\n",
    "# gpt4_tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "# gpt4_tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample input\n",
    "text = torch.randint(0, 100288, (1, 1024))\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(text)\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# def generate(model,\n",
    "#              tokenizer,\n",
    "#              prompt: str,\n",
    "#              n_tokens_to_gen: int = 200,\n",
    "#              sample: bool = True,\n",
    "#              top_k: int = 40):\n",
    "#     model.eval()\n",
    "\n",
    "#     input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "#     for token_n in range(n_tokens_to_gen):\n",
    "#         with torch.no_grad():\n",
    "#             indices_to_input = input_ids\n",
    "#             next_token_logits, loss = model(indices_to_input)\n",
    "#             next_token_logits = next_token_logits[:, -1]\n",
    "\n",
    "#         probs = F.softmax(next_token_logits, dim=-1)\n",
    "#         (batch, vocab_size) = probs.shape\n",
    "\n",
    "#         if top_k is not None:\n",
    "#             (values, indices) = torch.topk(probs, k=top_k)\n",
    "#             probs[probs < values[:, -1, None]] = 0\n",
    "#             probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "#         if sample:\n",
    "#             next_indices = torch.multinomial(probs, num_samples=1)\n",
    "#         else:\n",
    "#             next_indices = torch.argmax(probs, dim=-1)[:, None]\n",
    "\n",
    "#         input_ids = torch.cat([input_ids, next_indices], dim=1)\n",
    "\n",
    "#     output_completions = [tokenizer.decode(output.tolist()) for output in input_ids][0]\n",
    "\n",
    "#     return output_completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
