GPTConfig.block_size = 1024            
GPTConfig.vocab_size = 100288           
GPTConfig.n_layer = 16                 
GPTConfig.n_head = 16                 
GPTConfig.n_embd = 1024    
GPTConfig.attn_dropout = 0.0             
GPTConfig.batch_size = 4              
GPTConfig.learning_rate = 3e-4                
GPTConfig.epochs = 2
GPTConfig.weight_decay = 0.0001
GPTConfig.eps = 1e-8
GPTConfig.betas = (0.9, 0.97)
GPTConfig.training_backend = "nccl"
GPTConfig.clip_grad_norm_val = 1.0
GPTConfig.base_theta = 10000.0
GPTConfig.scale_factor = 1.0
GPTConfig.rng_seed = 42
GPTConfig.do_init_params = True
GPTConfig.eta_min = 3e-6
GPTConfig.gradient_accumulation_steps = 32
GPTConfig.pad_token_id = 100278